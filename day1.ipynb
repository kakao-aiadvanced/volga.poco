{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SnZ5WDtMlWo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUUEj-ljNybm",
        "outputId": "0b8346ef-3576-41f0-8155-aafb052b5c15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.55.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "# The OpenAI client is initialized without any arguments.\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a haiku about recursion in programming.\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQkTDbhRNyi-",
        "outputId": "2762c1cb-edb3-4383-d283-bcee2597575d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Functions call themselves,  \\nLayers of code intertwine,  \\nInfinite loops dance.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few shot engineering\n",
        "\n",
        "- 영어를 한국어로 번역하는 5-shot prompt 를 작성하고 \"dog\"를 번역해보세요."
      ],
      "metadata": {
        "id": "bFmgHx9XQAph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "            한국어: \"고양이\", 영어: \"Cat\"\n",
        "            한국어: \"여우\", 영어: \"Fox\"\n",
        "            한국어: \"늑대\", 영어: \"Wolf\"\n",
        "            한국어: \"곰\", 영어: \"Bear\"\n",
        "            한국어: \"쥐\", 영어: \"Mouse\"\n",
        "\n",
        "            영어: \"Dog\", 한국어: ?\n",
        "            \"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_iJF61xNyll",
        "outputId": "82a10669-cd09-45ff-ad85-1756be67e21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='영어 \"Dog\"에 해당하는 한국어는 \"개\"입니다.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 영화 리뷰에 대한 sentiment (positive or negative) 를 결정하는 5-shot prompt 를 작성하고 \"The storyline was dull and uninspiring.\" 에 대한 결과를 확인해보세요."
      ],
      "metadata": {
        "id": "27ivsdE7Ry6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "            \"영화가 너무 재밌었어요.\": Positive,\n",
        "            \"영화에 신파극이 나와서 혼란스러웠어요\": Negative,\n",
        "            \"영화가 끝나고나서 내용이 기억에 남지 않았어요\": Negative,\n",
        "            \"하품이 나왔지만 전개가 깔끔했습니다!\": Positive,\n",
        "            \"원작을 잘 따라간 스토리입니다\": Positive\n",
        "\n",
        "            \"The storyline was dull and uninspiring.\": ?\n",
        "            \"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq5BewmENyoK",
        "outputId": "cc491574-c186-40f2-d60d-efb7122cd991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='\"The storyline was dull and uninspiring.\" would be classified as Negative.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 자연어를 SQL 쿼리로 바꿔주는 few-shot prompt 를 작성해보세요.\n",
        "\n",
        "아래 1~5 의 \"write your prompt\" 영역에 오른쪽 SQL 쿼리에 해당하는 자연어 문장을 작성해보세요."
      ],
      "metadata": {
        "id": "485RHY_jTO2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "Convert the following natural language requests into SQL queries:\n",
        "1. \"급여가 50,000보다 큰 직원들의 모든 정보를 조회한다\": SELECT * FROM employees WHERE salary > 50000;\n",
        "2. \"재고가 0인 제품들의 모든 정보를 조회한다\": SELECT * FROM products WHERE stock = 0;\n",
        "3. \"수학 점수가 90보다 높은 학생들의 이름을 조회한다\": SELECT name FROM students WHERE math_score > 90;\n",
        "4. \"최근 30일 이내에 이루어진 주문들의 모든 정보를 조회한다\": SELECT * FROM orders WHERE order_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY);\n",
        "5. \"고객들을 도시별로 그룹화하여 각 도시의 고객 수를 계산한다\": SELECT city, COUNT(*) FROM customers GROUP BY city;\n",
        "\n",
        "Request: \"Find the average salary of employees in the marketing department.\"\n",
        "SQL Query:\n",
        "            \"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U_pj5-wNyqh",
        "outputId": "daf1682d-8dfa-4efd-ee12-16eb457e063c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"```sql\\nSELECT AVG(salary) FROM employees WHERE department = 'marketing';\\n```\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain of Thought"
      ],
      "metadata": {
        "id": "73govFbHUnVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 문제를 푸는 Chain of thought prompt 를 작성해보세요."
      ],
      "metadata": {
        "id": "1hUtLD3IVEwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "# Simple - 1\n",
        "Solve the following problem step-by-step: 23 + 47\n",
        "\n",
        "Step-by-step solution:\n",
        "1. 23 + 47 = (20 + 3) + 47\n",
        "2. (20 + 3) + (40 + 7)\n",
        "3. 20 + 3 + 40 + 7 = 20 + 40 + (7 + 3)\n",
        "4. 20 + 40 + 10 = 70\n",
        "\n",
        "Answer: 70\n",
        "\n",
        "# Simple - 2\n",
        "Solve the following problem step-by-step: 123 - 58\n",
        "\n",
        "Step-by-step solution:\n",
        "1. 123 - 58 = (118 + 5) - (50 + 8)\n",
        "2. 118 + 5 - 50 - 8 = 110 - 45\n",
        "3. 110 - 45 = (100 + 10) - (40 + 5)\n",
        "4. 100 - 40 + 10 -5 = 60 + 5\n",
        "\n",
        "Answer: 65\n",
        "\n",
        "# Simple 결과 확인\n",
        "Solve the following problem step-by-step: 345 + 678 - 123\n",
        "\n",
        "Step-by-step solution:\n",
        "1. Check the response\n",
        "2. Check the response\n",
        "3. Check the response\n",
        "\n",
        "Answer: 900\n",
        "            \"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_oQo1PNNys-",
        "outputId": "e2a0204d-14bd-4dfc-af54-cbace0c4e5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"Let's solve the problem \\\\( 345 + 678 - 123 \\\\) step by step.\\n\\nStep-by-step solution:\\n1. First, calculate \\\\( 345 + 678 \\\\).\\n   - Break it down: \\\\( 345 + 678 = (300 + 40 + 5) + (600 + 70 + 8) \\\\)\\n   - Combine the hundreds: \\\\( 300 + 600 = 900 \\\\)\\n   - Combine the tens: \\\\( 40 + 70 = 110 \\\\)\\n   - Combine the units: \\\\( 5 + 8 = 13 \\\\)\\n   - Now add those sums together: \\\\( 900 + 110 + 13 = 1023 \\\\)\\n\\n2. Next, subtract \\\\( 123 \\\\) from \\\\( 1023 \\\\).\\n   - Break it down: \\\\( 1023 - 123 = (1000 + 20 + 3) - (100 + 20 + 3) \\\\)\\n   - Subtract the hundreds: \\\\( 1000 - 100 = 900 \\\\)\\n   - Subtract the tens: \\\\( 20 - 20 = 0 \\\\)\\n   - Subtract the units: \\\\( 3 - 3 = 0 \\\\)\\n\\n3. We are left with:\\n   - \\\\( 900 + 0 + 0 = 900 \\\\)\\n\\nThus, the final answer is:\\n\\nAnswer: 900\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 문제 (Intermediate-1, Intermediate-2) 를 푸는 과정을 담은 CoT 예시를 작성해보세요."
      ],
      "metadata": {
        "id": "0fEsCxo1WggA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "# Intermediate - 1\n",
        "Solve the following logic puzzle step-by-step:\n",
        "Three friends, Alice, Bob, and Carol, have different favorite colors: red, blue, and green. We know that:\n",
        "1. Alice does not like red.\n",
        "2. Bob does not like blue.\n",
        "3. Carol likes green.\n",
        "\n",
        "Determine the favorite color of each friend.\n",
        "\n",
        "Step-by-step solution:\n",
        "1. 앨리스는 red를 좋아하지 않음 (blue, green은 가능성 있음)\n",
        "2. Bob은 Blue를 좋아하지 않음 (red, green은 가능성이 있음 만약 앨리스가 blue일 경우 두개 다 가능, 반대로 green일 경우 blue만 가능함)\n",
        "3. Carol은 green을 좋아함, 따라서 alice, Bob은 Green을 좋아하지 않음\n",
        "4. 앨리스는 blue만 가능성이 있음 따라서 Blue를 좋아함\n",
        "5. Bob은 red만 가능성이 있음 따라서 Red를 좋아함\n",
        "\n",
        "Answer:\n",
        "- Alice:\n",
        "- Bob:\n",
        "- Carol:\n",
        "\n",
        "# Intermediate - 2\n",
        "Solve the following logic puzzle step-by-step:\n",
        "Four people (A, B, C, D) are sitting in a row. We know that:\n",
        "1. A is not next to B.\n",
        "2. B is next to C.\n",
        "3. C is not next to D.\n",
        "\n",
        "Determine the possible seating arrangements.\n",
        "\n",
        "Step-by-step solution:\n",
        "B는 A 옆이 아님. * B * A *, * A * B * 가 가능함\n",
        "B옆에는 C가 있음 C B * A *, * B C * A *, * A C B *, * A * C B *\n",
        "C는 D옆일수 없음: CBDA, DBCA, BCAD, ACBD, DACB\n",
        "\n",
        "Answer:\n",
        "- Possible arrangements: BCAD, CABD\n",
        "            \"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPtflmGXWX79",
        "outputId": "59ee8955-4f2c-4a8b-f03f-cb811729d785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"Let's solve both logic puzzles step-by-step.\\n\\n## Intermediate - 1\\n\\nWe need to determine the favorite colors of Alice, Bob, and Carol based on the clues given.\\n\\n1. **Alice does not like red.**  \\n   - This means Alice could like either blue or green.\\n\\n2. **Bob does not like blue.**  \\n   - This means Bob could like either red or green.\\n\\n3. **Carol likes green.**  \\n   - Since Carol has already chosen green, Alice and Bob cannot like green.\\n\\nFrom the clues, we can summarize the possibilities:\\n\\n- **Alice**: Can like blue (since she doesn't like red)  \\n- **Bob**: Can like red (since he doesn't like blue)  \\n- **Carol**: Likes green (already given)\\n\\nSince Carol likes green, and Alice cannot like red (which leads to blue being the only option for Alice), we conclude:\\n\\n- Alice must like **blue**.\\n- Bob must then like **red** (since he cannot like blue and Carol took green).\\n- Carol likes **green** (from the given information).\\n\\n**Final Answer:**\\n- Alice: Blue\\n- Bob: Red\\n- Carol: Green\\n\\n---\\n\\n## Intermediate - 2\\n\\nWe need to determine the possible seating arrangements for A, B, C, and D based on the clues provided.\\n\\n1. **A is not next to B.**  \\n   - This means pairs like AB and BA are not allowed.\\n\\n2. **B is next to C.**  \\n   - This means B and C must be adjacent; so arrangements could look like (B C) or (C B).\\n\\n3. **C is not next to D.**  \\n   - This means C cannot be adjacent to D, ruling out arrangements like CD or DC.\\n\\nNow let's analyze potential seating based on these rules:\\n\\nGiven that B must be next to C, let's start by pushing those two together in different arrangements while respecting the other constraints.\\n\\nAssuming (B C) as a block, there are two variations:\\n\\n1. **B C A D**\\n2. **B C D A**\\n\\n- For (C B), the arrangements would be:\\n3. **C B A D**\\n4. **C B D A**\\n\\nNow checking constraints:\\n\\n- Arrangement (1) B C A D: A is not next to B; satisfies all conditions.\\n- Arrangement (2) B C D A: C is next to D; violates the condition.\\n- Arrangement (3) C B A D: A is not next to B; satisfies all conditions.\\n- Arrangement (4) C B D A: C is next to D; violates the condition.\\n\\nThus, the valid arrangements that fit all rules are:\\n\\n**Final Answer:**\\n- Possible arrangements: B C A D, C B A D\\n\\nThese arrangements ensure A is not next to B, B is next to C, and C is not next to D.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering Evaluation 자동화 (Using Prompt Bench)"
      ],
      "metadata": {
        "id": "rAShOgg8ao0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install promptbench openai==1.3.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uivaFe3fapTL",
        "outputId": "3bd6a12e-57fd-4ae0-c501-ada4cbb46e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting promptbench\n",
            "  Downloading promptbench-0.0.4-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting openai==1.3.7\n",
            "  Downloading openai-1.3.7-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting anyio<4,>=3.5.0 (from openai==1.3.7)\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.3.7) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.3.7) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.3.7) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.3.7) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.3.7) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.11/dist-packages (from openai==1.3.7) (4.12.2)\n",
            "Collecting autocorrect==2.6.1 (from promptbench)\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.25.0 (from promptbench)\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting datasets>=2.15.0 (from promptbench)\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting nltk==3.8.1 (from promptbench)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sentencepiece==0.1.99 (from promptbench)\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting tokenizers==0.15.0 (from promptbench)\n",
            "  Downloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from promptbench) (2.6.0+cu124)\n",
            "Collecting tqdm>4 (from openai==1.3.7)\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.38.0 (from promptbench)\n",
            "  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==10.3.0 (from promptbench)\n",
            "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting google-generativeai==0.4.0 (from promptbench)\n",
            "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting dashscope==1.14.1 (from promptbench)\n",
            "  Downloading dashscope-1.14.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting einops==0.7.0 (from promptbench)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers-stream-generator==0.0.5 (from promptbench)\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchvision==0.17.0 (from promptbench)\n",
            "  Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting matplotlib==3.8.3 (from promptbench)\n",
            "  Downloading matplotlib-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting tiktoken==0.6.0 (from promptbench)\n",
            "  Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->promptbench) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->promptbench) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->promptbench) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->promptbench) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->promptbench) (0.29.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->promptbench) (0.5.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from dashscope==1.14.1->promptbench) (3.11.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dashscope==1.14.1->promptbench) (2.32.3)\n",
            "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai==0.4.0->promptbench)\n",
            "  Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0->promptbench) (2.38.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0->promptbench) (2.24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0->promptbench) (5.29.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.3->promptbench) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.3->promptbench) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.3->promptbench) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.3->promptbench) (1.4.8)\n",
            "Collecting numpy>=1.17 (from accelerate==0.25.0->promptbench)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.3->promptbench) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.3->promptbench) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1->promptbench) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1->promptbench) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1->promptbench) (2024.11.6)\n",
            "Collecting torch>=2.1.1 (from promptbench)\n",
            "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->promptbench) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->promptbench) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->promptbench) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->promptbench) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.1->promptbench) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.1->promptbench)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch>=2.1.1->promptbench)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0->promptbench) (1.26.1)\n",
            "Collecting protobuf (from google-generativeai==0.4.0->promptbench)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.1->promptbench) (12.5.82)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.5.0->openai==1.3.7) (3.10)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.15.0->promptbench) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.15.0->promptbench)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.15.0->promptbench) (2.2.2)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets>=2.15.0 (from promptbench)\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pyarrow-hotfix (from datasets>=2.15.0->promptbench)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting datasets>=2.15.0 (from promptbench)\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting xxhash (from datasets>=2.15.0->promptbench)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets>=2.15.0->promptbench)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch>=2.1.1->promptbench)\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.3.7) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.3.7) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.7) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.3.7) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.3.7) (2.27.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope==1.14.1->promptbench) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope==1.14.1->promptbench) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope==1.14.1->promptbench) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope==1.14.1->promptbench) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope==1.14.1->promptbench) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope==1.14.1->promptbench) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope==1.14.1->promptbench) (1.18.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai==0.4.0->promptbench) (1.69.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.4.0->promptbench) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.4.0->promptbench) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.4.0->promptbench) (4.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.3->promptbench) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dashscope==1.14.1->promptbench) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dashscope==1.14.1->promptbench) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.1->promptbench) (3.0.2)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets>=2.15.0->promptbench)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.15.0->promptbench) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.15.0->promptbench) (2025.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.1.1->promptbench) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0->promptbench) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0->promptbench) (1.71.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.4.0->promptbench) (0.6.1)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0->promptbench)\n",
            "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading promptbench-0.0.4-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dashscope-1.14.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_generativeai-0.4.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m855.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m598.7/598.7 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autocorrect, transformers-stream-generator\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622364 sha256=22f88ab68b1d7c412a867802e42a607befa96b6ce8a4fd4646e9192da04b800f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/90/99/807a5ad861ce5d22c3c299a11df8cba9f31524f23ae6e645cb\n",
            "  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12425 sha256=527f037b747882f9519d80339278743faee14f2b2977fa0c336558a79d0fc92c\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/e8/f0/b3c58c12d1ffe60bcc8c7d121115f26b2c1878653edfca48db\n",
            "Successfully built autocorrect transformers-stream-generator\n",
            "Installing collected packages: sentencepiece, xxhash, triton, tqdm, pyarrow-hotfix, protobuf, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fsspec, einops, dill, autocorrect, anyio, tiktoken, nvidia-cusolver-cu12, nvidia-cudnn-cu12, nltk, multiprocess, torch, tokenizers, openai, matplotlib, grpcio-status, dashscope, transformers, torchvision, datasets, accelerate, transformers-stream-generator, google-ai-generativelanguage, google-generativeai, promptbench\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.3\n",
            "    Uninstalling protobuf-5.29.3:\n",
            "      Successfully uninstalled protobuf-5.29.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.9.0\n",
            "    Uninstalling anyio-4.9.0:\n",
            "      Successfully uninstalled anyio-4.9.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.66.3\n",
            "    Uninstalling openai-1.66.3:\n",
            "      Successfully uninstalled openai-1.66.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.71.0\n",
            "    Uninstalling grpcio-status-1.71.0:\n",
            "      Successfully uninstalled grpcio-status-1.71.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.49.0\n",
            "    Uninstalling transformers-4.49.0:\n",
            "      Successfully uninstalled transformers-4.49.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.5.2\n",
            "    Uninstalling accelerate-1.5.2:\n",
            "      Successfully uninstalled accelerate-1.5.2\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.8.4\n",
            "    Uninstalling google-generativeai-0.8.4:\n",
            "      Successfully uninstalled google-generativeai-0.8.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.0 which is incompatible.\n",
            "google-genai 1.5.0 requires anyio<5.0.0dev,>=4.8.0, but you have anyio 3.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.3.0 accelerate-0.25.0 anyio-3.7.1 autocorrect-2.6.1 dashscope-1.14.1 datasets-2.19.2 dill-0.3.8 einops-0.7.0 fsspec-2024.3.1 google-ai-generativelanguage-0.4.0 google-generativeai-0.4.0 grpcio-status-1.62.3 matplotlib-3.8.3 multiprocess-0.70.16 nltk-3.8.1 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 openai-1.3.7 promptbench-0.0.4 protobuf-4.25.6 pyarrow-hotfix-0.6 sentencepiece-0.1.99 tiktoken-0.6.0 tokenizers-0.15.0 torch-2.2.0 torchvision-0.17.0 tqdm-4.66.1 transformers-4.38.0 transformers-stream-generator-0.0.5 triton-2.2.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "anyio",
                  "google",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "0a38ae17a4f54c1b8bb0a87c75084f20"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import promptbench as pb\n",
        "\n",
        "# print all supported datasets in promptbench\n",
        "print('All supported datasets: ')\n",
        "print(pb.SUPPORTED_DATASETS)\n",
        "\n",
        "# load a dataset, sst2, for instance.\n",
        "# if the dataset is not available locally, it will be downloaded automatically.\n",
        "dataset_name = \"gsm8k\"\n",
        "dataset = pb.DatasetLoader.load_dataset(dataset_name)\n",
        "\n",
        "# print the first 3 examples\n",
        "dataset[:3]"
      ],
      "metadata": {
        "id": "_xOvBjcxazdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print all supported models in promptbench\n",
        "print('All supported models: ')\n",
        "print(pb.SUPPORTED_MODELS)\n",
        "\n",
        "# load a model, gpt-3.5-turbo, for instance.\n",
        "# If model is openai/palm, need to provide openai_key/palm_key\n",
        "# If model is llama, vicuna, need to provide model dir\n",
        "model = pb.LLMModel(model='gpt-3.5-turbo',\n",
        "                    api_key = '',\n",
        "                    max_new_tokens=150)"
      ],
      "metadata": {
        "id": "iX25UN2nbQAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Auto Generation"
      ],
      "metadata": {
        "id": "qLtbAaj2b_3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Implement a method to automatically generate and test multiple prompt variations."
      ],
      "metadata": {
        "id": "jZj7YhUBcDd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task: Use an automated system to create a variety of prompts for sentiment analysis"
      ],
      "metadata": {
        "id": "PJvhQI7ScD7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\"\n",
        "            Create a script that generates multiple prompt variations for sentiment analysis.\n",
        "Example variations might include different phrasings, structures, and additional context.\n",
        "            \"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3iMJCoycAck",
        "outputId": "ef7d4c0b-7eda-4a6e-a2b6-044f4032399c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Certainly! Below is a script that generates multiple prompt variations for sentiment analysis. The prompts are structured to capture diverse phrasings, contexts, or target expressions while retaining the core intention of sentiment analysis.\\n\\n```python\\nimport random\\n\\ndef generate_sentiment_prompts(base_input):\\n    prompts = []\\n    \\n    # Different phrasings\\n    phrasing_variations = [\\n        f\"Analyze the sentiment of the following statement: \\'{base_input}\\'\",\\n        f\"What is the sentiment expressed in this text? \\'{base_input}\\'\",\\n        f\"Evaluate the emotional tone of the following: \\'{base_input}\\'\",\\n        f\"Determine the sentiment of the statement: \\'{base_input}\\'\",\\n        f\"Please assess the feelings conveyed in this text: \\'{base_input}\\'\",\\n        f\"What sentiment is reflected in this statement: \\'{base_input}\\'?\",\\n        f\"Identify the sentiment behind this text: \\'{base_input}\\'\",\\n    ]\\n    \\n    # Contextual variations\\n    contexts = [\\n        f\"I want to understand how people feel about this statement: \\'{base_input}\\'\",\\n        f\"This statement appears to express a certain emotion. Can you clarify? \\'{base_input}\\'\",\\n        f\"There’s a message in this text. What sentiment does it carry? \\'{base_input}\\'\",\\n        f\"Considering the following context, what sentiment can you detect? \\'{base_input}\\'\",\\n        f\"Given the recent events, analyze the sentiment in this statement: \\'{base_input}\\'\",\\n        f\"Reflecting on current trends, what is the sentiment of the following: \\'{base_input}\\'\",\\n    ]\\n    \\n    # Structure variations\\n    structure_variations = [\\n        f\"In the following phrase, what is the overall sentiment? \\'{base_input}\\'\",\\n        f\"This is a statement: \\'{base_input}\\'. Can you identify the sentiment in it?\",\\n        f\"Inspect this text and tell me the sentiment: \\'{base_input}\\'\",\\n        f\"From the following input: \\'{base_input}\\', what sentiment do you derive?\",\\n        f\"Here\\'s a sentence: \\'{base_input}\\'. What feelings does it express?\",\\n    ]\\n    \\n    # Combine variations into the prompts list\\n    prompts.extend(phrasing_variations)\\n    prompts.extend(contexts)\\n    prompts.extend(structure_variations)\\n    \\n    # Shuffle the prompts for randomness\\n    random.shuffle(prompts)\\n    \\n    return prompts\\n\\n# Example usage\\ntext_to_analyze = \"I really enjoyed the movie; it was fantastic!\"\\nsentiment_prompts = generate_sentiment_prompts(text_to_analyze)\\n\\n# Print the generated prompts\\nfor prompt in sentiment_prompts:\\n    print(prompt)\\n```\\n\\n### Explanation:\\n1. **Phrasing Variations:** Different ways to ask for sentiment analysis.\\n2. **Contextual Variations:** Adding context can change how the sentiment is perceived.\\n3. **Structure Variations:** Varying the structure can help test different interpreting mechanisms.\\n4. **Randomization:** Shuffles the generated prompts for a varied output every time.\\n\\n### Usage:\\nYou can call `generate_sentiment_prompts()` with any text input to get a list of varied prompts for analyzing sentiment. Each run will produce a different order and combination of prompts.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34TfHvJvdcNC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}